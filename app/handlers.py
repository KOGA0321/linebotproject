
# app/handlers.py

import os
from datetime import datetime
from openai import OpenAI
from linebot.v3.messaging.models import TextMessage, ReplyMessageRequest
from linebot.v3.webhooks               import MessageEvent
from dotenv import load_dotenv
from flask import current_app

# app/handlers.py ã®å…ˆé ­è¿‘ãã«è¿½è¨˜
from app.db import is_paid_user, save_log_to_sqlite,is_within_limit, increment_usage

from app.utils import client  # OpenAI ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’ä½œã£ã¦ã„ã‚‹ãªã‚‰ã“ã“ã‹ã‚‰


from app.emotion import classify_emotion_by_ai

from app.bot import messaging_api, handler

from app.db      import (
    fetch_last_n_logs,
    fetch_latest_weekly_report,
    save_log_to_sqlite,
    is_paid_user,
)
from app.bot     import messaging_api, handler

# .env ã‚’èª­ã¿è¾¼ã‚“ã§ç’°å¢ƒå¤‰æ•°ã‚’ã‚»ãƒƒãƒˆ
load_dotenv()

# OpenAI ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))



@handler.add(MessageEvent)
def handle_message(event: MessageEvent):
    # 1) ãƒ¦ãƒ¼ã‚¶ãƒ¼æƒ…å ±å–å¾— & ãƒ‡ãƒãƒƒã‚°ãƒ­ã‚°
    user_text   = event.message.text
    user_id     = event.source.user_id
    reply_token = event.reply_token

    if not is_within_limit(user_id):
        # ç„¡æ–™æ è¶…éæ™‚ã®è¿”ä¿¡
        reply = "ã”ã‚ã‚“ã­ã€ä»Šæ—¥ã¯ã‚‚ã†ç„¡æ–™æ ã®ä¸Šé™ã«é”ã—ã¡ã‚ƒã£ãŸã‚ˆğŸ˜¢\nã¾ãŸæ˜æ—¥è©¦ã—ã¦ã­ï¼"
        reply_text(event.reply_token, reply)
        return
    else:
        # ä½¿ã£ãŸå›æ•°ã‚’ã‚«ã‚¦ãƒ³ãƒˆã‚¢ãƒƒãƒ—
        increment_usage(user_id)

    log = current_app.logger

    # ãƒ‡ãƒãƒƒã‚°ãƒ­ã‚°ã‚’å‡ºåŠ›
    log.info(f"Received message: {user_text!r} from {user_id}")


    # 2) ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆçµ„ã¿ç«‹ã¦
    context_messages = []
    latest = fetch_latest_weekly_report(user_id)
    if latest:
        context_messages.append({
            "role": "system",
            "content": "ï¼ˆä»¥ä¸‹ã¯ä»Šé€±ã®é€±å ±ã§ã™ï¼‰\n" + latest
        })
    for u, a, emotion in fetch_last_n_logs(user_id, n=5):
        context_messages.append({"role":"user",      "content":u})
        context_messages.append({"role":"assistant", "content":a})
    context_messages.append({"role":"user", "content":user_text})

    # 3) ãƒ¢ãƒ‡ãƒ«é¸æŠï¼†GPTå‘¼ã³å‡ºã—
    is_paid = is_paid_user(user_id)
    model   = "gpt-4o" if is_paid else "gpt-3.5-turbo"

    

    response = client.chat.completions.create(
        model=model,
        messages=[{"role":"system","content":"ã‚ãªãŸã¯å…±æ„ŸåŠ›ã«å„ªã‚ŒãŸãƒ¡ãƒ³ã‚¿ãƒ«ã‚±ã‚¢AIã§ã™ã€‚ç›¸æ‰‹ã®æ°—æŒã¡ã«å¯„ã‚Šæ·»ã„ã€å„ªã—ãè¦ªèº«ã«ãªã£ã¦ç›¸è«‡ã«ã®ã£ã¦ãã ã•ã„ã€‚å …è‹¦ã—ã„æ•¬èªã¯æ§ãˆã¦ã€å‹é”ã®ã‚ˆã†ãªãƒ•ãƒ©ãƒƒãƒˆãªå£èª¿ã§è©±ã—ã¾ã—ã‚‡ã†ã€‚çŸ­ãç°¡æ½”ã«è¿”ç­”ã—ã€ä¸€æ–¹çš„ã«è§£æ±ºç­–ã‚’æŠ¼ã—ä»˜ã‘ã‚‹ã®ã§ã¯ãªãã€ä¸€ç·’ã«åŸå› ã‚’æ¢ã‚‹ã‚ˆã†ã«ã‚„ã‚Šã¨ã‚Šã—ã¦ãã ã•ã„ã€‚ç›¸æ‰‹ã®ç™ºè¨€ã«æ„Ÿæƒ…çš„ãªãƒ¯ãƒ¼ãƒ‰ãŒå«ã¾ã‚Œã¦ã„ã‚Œã°ã€ãã‚Œã«åˆã‚ã›ãŸå¯¾å¿œã‚’å¿ƒãŒã‘ã¦ãã ã•ã„ã€‚"}]
                 + context_messages
    )
    reply_text = response.choices[0].message.content.strip()
    print(f"[DEBUG] reply_text: {reply_text!r} (len={len(reply_text)})")
    if not reply_text.strip():
        print("[WARN] reply_text empty, substituting fallback")
        reply_text = "ã™ã¿ã¾ã›ã‚“ã€ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚"
    

    emotion = classify_emotion_by_ai(user_text)
    
    # 4) è¦ç´„ç”Ÿæˆï¼†DBä¿å­˜
    summary = client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[
            {"role":"system","content":"æ¬¡ã®ä¼šè©±ã‚’ä¸€æ–‡ã§è¦ç´„ã—ã¦ãã ã•ã„ã€‚"},
            {"role":"user","content":f"ãƒ¦ãƒ¼ã‚¶ãƒ¼:{user_text}\nAI:{reply_text}"}
        ]
    ).choices[0].message.content.strip()
    save_log_to_sqlite(user_id, user_text, reply_text,emotion, summary)

    # 5) LINE ã¸ä¸€åº¦ã ã‘è¿”ä¿¡
    log.debug("sending reply to LINEâ€¦")
    try:
        messaging_api.reply_message(
            ReplyMessageRequest(
                reply_token=reply_token,
                messages=[TextMessage(text=reply_text)]
            )
        )
        log.debug(f"reply sent successfully to {user_id}")
    except Exception as e:
        log.error(f"failed to send reply: {e}")
        raise

